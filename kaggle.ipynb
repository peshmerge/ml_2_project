{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4457395c-1f41-4bdc-8ad0-0c83b1021ccb",
   "metadata": {},
   "source": [
    "# Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9ce2f-ec4e-4517-8fcf-f20989d7cac1",
   "metadata": {},
   "source": [
    "## Installing required libraries and downloading the dataset\n",
    "Note that the location of where the `kaggle` library is installed might differ. Change that as you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63db894b-7d13-4987-aa32-993a39a48fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !~/.local/bin/kaggle competitions download -c tensorflow-great-barrier-reef\n",
    "# !pip install numpy\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616f19e-a137-490b-b359-bd3e2ee69577",
   "metadata": {},
   "source": [
    "## Importing required libraries\n",
    "Another note: `greatbarrierreef` library requires you to have `python 3.7.10`. If you have `python 3.7.10` and you have a folder in your current directory called `greatbarrierreef` then, you can uncomment the library import below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9106fec3-a508-4e60-8a1d-b876cd93f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import ast  ## Change str -> list.\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "INPUT_DIR = './input/'\n",
    "sys.path.insert(0, INPUT_DIR)\n",
    "\n",
    "# import greatbarrierreef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbb96f7-2b77-43b3-bfc3-9cbc4c408eb9",
   "metadata": {},
   "source": [
    "## Reading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3b2ed1-f0e3-4237-a29f-8701d2040b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-0</td>\n",
       "      <td>[]</td>\n",
       "      <td>input/train_images/video_0/0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1</td>\n",
       "      <td>[]</td>\n",
       "      <td>input/train_images/video_0/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0-2</td>\n",
       "      <td>[]</td>\n",
       "      <td>input/train_images/video_0/2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0-3</td>\n",
       "      <td>[]</td>\n",
       "      <td>input/train_images/video_0/3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>[]</td>\n",
       "      <td>input/train_images/video_0/4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   video_id  sequence  video_frame  sequence_frame image_id annotations  \\\n",
       "0         0     40258            0               0      0-0          []   \n",
       "1         0     40258            1               1      0-1          []   \n",
       "2         0     40258            2               2      0-2          []   \n",
       "3         0     40258            3               3      0-3          []   \n",
       "4         0     40258            4               4      0-4          []   \n",
       "\n",
       "                           img_path  \n",
       "0  input/train_images/video_0/0.jpg  \n",
       "1  input/train_images/video_0/1.jpg  \n",
       "2  input/train_images/video_0/2.jpg  \n",
       "3  input/train_images/video_0/3.jpg  \n",
       "4  input/train_images/video_0/4.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('input/train.csv')\n",
    "df_train['img_path'] = os.path.join('input/train_images')+\"/video_\"+df_train.video_id.astype(str)+\"/\"+df_train.video_frame.astype(str)+\".jpg\"\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98bfbc34-1c18-419e-84e1-e1c148553a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images with annotations: 4919\n",
      "Images without annotations: 18582\n"
     ]
    }
   ],
   "source": [
    "with_annotation = len(df_train[df_train['annotations'] != '[]'])\n",
    "without_annotation = len(df_train[df_train['annotations'] == '[]'])\n",
    "print('Images with annotations:', with_annotation)\n",
    "print('Images without annotations:', without_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0467a654-3d7a-4da8-bd58-fedca0600c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>video_frame</th>\n",
       "      <th>sequence_frame</th>\n",
       "      <th>image_id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>img_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0-16</td>\n",
       "      <td>[{'x': 559, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>input/train_images/video_0/16.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>[{'x': 558, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>input/train_images/video_0/17.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0-18</td>\n",
       "      <td>[{'x': 557, 'y': 213, 'width': 50, 'height': 32}]</td>\n",
       "      <td>input/train_images/video_0/18.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0-19</td>\n",
       "      <td>[{'x': 556, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>input/train_images/video_0/19.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>40258</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0-20</td>\n",
       "      <td>[{'x': 555, 'y': 214, 'width': 50, 'height': 32}]</td>\n",
       "      <td>input/train_images/video_0/20.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    video_id  sequence  video_frame  sequence_frame image_id  \\\n",
       "16         0     40258           16              16     0-16   \n",
       "17         0     40258           17              17     0-17   \n",
       "18         0     40258           18              18     0-18   \n",
       "19         0     40258           19              19     0-19   \n",
       "20         0     40258           20              20     0-20   \n",
       "\n",
       "                                          annotations  \\\n",
       "16  [{'x': 559, 'y': 213, 'width': 50, 'height': 32}]   \n",
       "17  [{'x': 558, 'y': 213, 'width': 50, 'height': 32}]   \n",
       "18  [{'x': 557, 'y': 213, 'width': 50, 'height': 32}]   \n",
       "19  [{'x': 556, 'y': 214, 'width': 50, 'height': 32}]   \n",
       "20  [{'x': 555, 'y': 214, 'width': 50, 'height': 32}]   \n",
       "\n",
       "                             img_path  \n",
       "16  input/train_images/video_0/16.jpg  \n",
       "17  input/train_images/video_0/17.jpg  \n",
       "18  input/train_images/video_0/18.jpg  \n",
       "19  input/train_images/video_0/19.jpg  \n",
       "20  input/train_images/video_0/20.jpg  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annotated = df_train[df_train['annotations'].astype(str) != \"[]\"]\n",
    "df_annotated['annotations'] = df_train['annotations'].apply(ast.literal_eval)\n",
    "df_annotated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650d1a7-663e-44f8-80c9-2298dd59a664",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "Steps taken:\n",
    "1. Crop all the images with annotation to only get the Starfish samples.\n",
    "2. Resize the images to 200x200 with upscaling using Lanczos method.\n",
    "3. (WIP) Apply data augmentations:\n",
    "    - Rotation\n",
    "    - Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2cbbd605-cea3-42a2-a642-b6a473a62ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4919/4919 [02:14<00:00, 36.48it/s]\n"
     ]
    }
   ],
   "source": [
    "img_data = []\n",
    "\n",
    "for img_id in tqdm(df_annotated.index, position=0, leave=True):\n",
    "    image_path = df_annotated['img_path'][5474]\n",
    "    img = Image.open(image_path)\n",
    "    for box in df_annotated['annotations'][5474]:\n",
    "        area = [box['x'], box['y'], box['x']+box['width'], box['y']+box['height']]\n",
    "        cropped_img = img.crop(area).resize((200, 200), resample=Image.ANTIALIAS)\n",
    "        pil_image = cropped_img.convert('RGB')\n",
    "        open_cv_image = np.array(pil_image)\n",
    "        img_data.append(open_cv_image)\n",
    "\n",
    "img_data = np.array(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6536e19-19e5-4079-89f8-fd4575551518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7283ff-85c8-480b-ab42-8a256af12c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f461ca-0024-4a5f-8f12-bd5b74b5a974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
